{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "#The cv2 module is the main module in OpenCV that provides developers with an easy-to-use interface for working with image and video processing functions\n",
    "# it is used for frame processing\n",
    "import cv2\n",
    "\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "\n",
    "# It's a landmark's facial detector with pre-trained models, the dlib is used to estimate the location of 68 coordinates (x, y) that map the facial points on a person's face\n",
    "import dlib\n",
    "\n",
    "# A series of convenience functions to make basic image processing functions such as translation, rotation, resizing, skeletonization, displaying Matplotlib images, sorting contours, detecting edges, and much more easier with OpenCV and both Python 2.7 and Python 3.\n",
    "from imutils import face_utils\n",
    "\n",
    "\n",
    "from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sounddevice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the video capture object (0 represents the default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face detector and facial landmarks predictor from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Define status variables for the blink detection\n",
    "sleep = 0\n",
    "drowsy = 0\n",
    "active = 0\n",
    "status = \"\"\n",
    "color = (0, 0, 0)\n",
    "\n",
    "# Define functions for computing distances and checking blinks\n",
    "# It is calculating the distance between 2 landmarks \n",
    "def compute(ptA, ptB):\n",
    "    dist = np.linalg.norm(ptA - ptB)\n",
    "    return dist\n",
    "\n",
    "# a and f are long distances, bd and ce are the short distances \n",
    "# In this we are calculating the ratio which is used for checking whether eyes are closed or not\n",
    "# Here we are calculating the EAR (Eye Aspect Ratio)\n",
    "def blinked(a, b, c, d, e, f):\n",
    "    up = compute(b, d) + compute(c, e)\n",
    "    down = compute(a, f)\n",
    "    ratio = up / (2.0 * down)\n",
    "    \n",
    "    # Check for blinks based on ratio\n",
    "    if ratio > 0.25:\n",
    "        return 2\n",
    "    elif 0.21 <= ratio <= 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define a function to perform OCR on a frame and print the extracted text\n",
    "# def perform_ocr(frame):\n",
    "#     # Convert the frame to grayscale for better OCR accuracy\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Apply thresholding (binarization)\n",
    "#     _, binary_frame = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#     # Use Tesseract to extract text from the preprocessed frame\n",
    "#     extracted_text = pytesseract.image_to_string(binary_frame, lang='eng')\n",
    "\n",
    "#     # Perform OCR using pytesseract on the grayscale frame\n",
    "#     # text = pytesseract.image_to_string(gray)\n",
    "\n",
    "#     # Print the extracted text in the console\n",
    "#     print(\"Extracted Text:\", extracted_text)\n",
    "\n",
    "# Continuously read frames from the video capture object\n",
    "\n",
    "\n",
    "# Play alarm sound when sleeping state is detected\n",
    "# def play_alarm():\n",
    "#     # unique_alias = str(uuid.uuid4())\n",
    "#     playsound(\"alarm.wav\", block=False)\n",
    "#     return \n",
    "\n",
    "def play_alarm():\n",
    "    def alarm_sound():\n",
    "        duration = 2  # Set the duration of the alarm sound\n",
    "        fs = 44100  # Set the sampling frequency\n",
    "        t = np.linspace(0, duration, int(fs * duration), False)  # Generate time vector\n",
    "        data = np.sin(2 * np.pi * 440 * t)  # Generate sine wave data\n",
    "        sd.play(data, samplerate=fs, blocking=True)  # Play the sound\n",
    "\n",
    "    # Start a separate thread to play the alarm sound\n",
    "    alarm_thread = threading.Thread(target=alarm_sound)\n",
    "    alarm_thread.start()\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector(gray)\n",
    "    face_frame = frame.copy()\n",
    "    \n",
    "    # Process each detected face\n",
    "    for face in faces:\n",
    "        # It is used for finding the corner coordinates\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "\n",
    "        # Draw rectangles around detected faces\n",
    "        cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Get facial landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        # Process eye blinks\n",
    "        left_blink = blinked(landmarks[36], landmarks[37], landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "        right_blink = blinked(landmarks[42], landmarks[43], landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "\n",
    "        # Judge the eye blinks\n",
    "        if left_blink == 0 or right_blink == 0:\n",
    "            sleep += 1\n",
    "            drowsy = 0\n",
    "            active = 0\n",
    "            if sleep > 6:\n",
    "                status = \"--SLEEPING--\"\n",
    "                color = (255, 0, 0)\n",
    "                \n",
    "                # Play alarm sound when the status is \"SLEEPING\"\n",
    "                # playsound(\"alarm.wav\")\n",
    "                play_alarm()\n",
    "\n",
    "        elif left_blink == 1 or right_blink == 1:\n",
    "            sleep = 0\n",
    "            active = 0\n",
    "            drowsy += 1\n",
    "            if drowsy > 6:\n",
    "                status = \"-Drowsy-\"\n",
    "                color = (0, 0, 255)\n",
    "        else:\n",
    "            drowsy = 0\n",
    "            sleep = 0\n",
    "            active += 1\n",
    "            if active > 6:\n",
    "                status = \"Active\"\n",
    "                color = (0, 255, 0)\n",
    "        \n",
    "        # Display status on the frame\n",
    "        cv2.putText(frame, status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "\n",
    "        # Draw facial landmarks on the face frame\n",
    "        for n in range(0, 68):\n",
    "            (x, y) = landmarks[n]\n",
    "            cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "    \n",
    "    # Perform OCR and print the extracted text\n",
    "    # perform_ocr(frame)\n",
    "\n",
    "    # Show the original frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Show the frame with detected faces and landmarks\n",
    "    if face_frame is not None:\n",
    "        cv2\n",
    "\n",
    "    cv2.imshow(\"Face Frame\", face_frame)\n",
    "\n",
    "    # Check for 'q' key to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
