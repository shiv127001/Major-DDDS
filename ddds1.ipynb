{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the video capture object (0 represents the default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face detector and facial landmarks predictor from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Define status variables for the blink detection\n",
    "sleep = 0\n",
    "drowsy = 0\n",
    "active = 0\n",
    "status = \"\"\n",
    "color = (0, 0, 0)\n",
    "\n",
    "# Define functions for computing distances and checking blinks\n",
    "def compute(ptA, ptB):\n",
    "    dist = np.linalg.norm(ptA - ptB)\n",
    "    return dist\n",
    "\n",
    "def blinked(a, b, c, d, e, f):\n",
    "    up = compute(b, d) + compute(c, e)\n",
    "    down = compute(a, f)\n",
    "    ratio = up / (2.0 * down)\n",
    "    \n",
    "    # Check for blinks based on ratio\n",
    "    if ratio > 0.25:\n",
    "        return 2\n",
    "    elif 0.21 <= ratio <= 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define a function to perform OCR on a frame and print the extracted text\n",
    "def perform_ocr(frame):\n",
    "    # Convert the frame to grayscale for better OCR accuracy\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding (binarization)\n",
    "    _, binary_frame = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Use Tesseract to extract text from the preprocessed frame\n",
    "    extracted_text = pytesseract.image_to_string(binary_frame, lang='eng')\n",
    "\n",
    "    # Perform OCR using pytesseract on the grayscale frame\n",
    "    # text = pytesseract.image_to_string(gray)\n",
    "\n",
    "    # Print the extracted text in the console\n",
    "    print(\"Extracted Text:\", extracted_text)\n",
    "\n",
    "# Continuously read frames from the video capture object\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector(gray)\n",
    "    face_frame = frame.copy()\n",
    "    \n",
    "    # Process each detected face\n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "\n",
    "        # Draw rectangles around detected faces\n",
    "        cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Get facial landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        # Process eye blinks\n",
    "        left_blink = blinked(landmarks[36], landmarks[37], landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "        right_blink = blinked(landmarks[42], landmarks[43], landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "\n",
    "        # Judge the eye blinks\n",
    "        if left_blink == 0 or right_blink == 0:\n",
    "            sleep += 1\n",
    "            drowsy = 0\n",
    "            active = 0\n",
    "            if sleep > 6:\n",
    "                status = \"SLEEPING\"\n",
    "                color = (255, 0, 0)\n",
    "                \n",
    "                # Play alarm sound when the status is \"SLEEPING\"\n",
    "                playsound(\"alarm.wav\")\n",
    "\n",
    "        elif left_blink == 1 or right_blink == 1:\n",
    "            sleep = 0\n",
    "            active = 0\n",
    "            drowsy += 1\n",
    "            if drowsy > 6:\n",
    "                status = \"Drowsy\"\n",
    "                color = (0, 0, 255)\n",
    "        else:\n",
    "            drowsy = 0\n",
    "            sleep = 0\n",
    "            active += 1\n",
    "            if active > 6:\n",
    "                status = \"Active\"\n",
    "                color = (0, 255, 0)\n",
    "        \n",
    "        # Display status on the frame\n",
    "        cv2.putText(frame, status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "\n",
    "        # Draw facial landmarks on the face frame\n",
    "        for n in range(0, 68):\n",
    "            (x, y) = landmarks[n]\n",
    "            cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "    \n",
    "    # Perform OCR and print the extracted text\n",
    "    perform_ocr(frame)\n",
    "\n",
    "    # Show the original frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Show the frame with detected faces and landmarks\n",
    "    if face_frame is not None:\n",
    "        cv2\n",
    "\n",
    "    cv2.imshow(\"Face Frame\", face_frame)\n",
    "\n",
    "    # Check for 'q' key to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing necessary libraries\n",
    "# import cv2\n",
    "# import pytesseract\n",
    "# import numpy as np\n",
    "# import dlib\n",
    "# from imutils import face_utils\n",
    "\n",
    "# # Initialize the video capture object (0 represents the default webcam)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Initialize the face detector and facial landmarks predictor from dlib\n",
    "# detector = dlib.get_frontal_face_detector()\n",
    "# predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# # Define status variables for the blink detection\n",
    "# sleep = 0\n",
    "# drowsy = 0\n",
    "# active = 0\n",
    "# status = \"\"\n",
    "# color = (0, 0, 0)\n",
    "\n",
    "# # Define functions for computing distances and checking blinks\n",
    "# def compute(ptA, ptB):\n",
    "#     dist = np.linalg.norm(ptA - ptB)\n",
    "#     return dist\n",
    "\n",
    "# def blinked(a, b, c, d, e, f):\n",
    "#     up = compute(b, d) + compute(c, e)\n",
    "#     down = compute(a, f)\n",
    "#     ratio = up / (2.0 * down)\n",
    "    \n",
    "#     # Check for blinks based on ratio\n",
    "#     if ratio > 0.25:\n",
    "#         return 2\n",
    "#     elif 0.21 <= ratio <= 0.25:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# # Define a function to perform OCR on a frame and print the extracted text\n",
    "# def perform_ocr(frame):\n",
    "#     # Convert the frame to grayscale for better OCR accuracy\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Perform OCR using pytesseract on the grayscale frame\n",
    "#     text = pytesseract.image_to_string(gray)\n",
    "\n",
    "#     # Print the extracted text in the console\n",
    "#     print(\"Extracted Text:\", text)\n",
    "\n",
    "# # Continuously read frames from the video capture object\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Check if the frame is read successfully\n",
    "#     if not ret:\n",
    "#         print(\"Error: Failed to read frame.\")\n",
    "#         break\n",
    "\n",
    "#     # Convert the frame to grayscale\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Detect faces in the grayscale frame\n",
    "#     faces = detector(gray)\n",
    "#     face_frame = frame.copy()\n",
    "    \n",
    "#     # Process each detected face\n",
    "#     for face in faces:\n",
    "#         x1 = face.left()\n",
    "#         y1 = face.top()\n",
    "#         x2 = face.right()\n",
    "#         y2 = face.bottom()\n",
    "\n",
    "#         # Draw rectangles around detected faces\n",
    "#         cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "#         # Get facial landmarks\n",
    "#         landmarks = predictor(gray, face)\n",
    "#         landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "#         # Process eye blinks\n",
    "#         left_blink = blinked(landmarks[36], landmarks[37], landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "#         right_blink = blinked(landmarks[42], landmarks[43], landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "\n",
    "#         # Judge the eye blinks\n",
    "#         if left_blink == 0 or right_blink == 0:\n",
    "#             sleep += 1\n",
    "#             drowsy = 0\n",
    "#             active = 0\n",
    "#             if sleep > 6:\n",
    "#                 status = \"SLEEPING !!!!\"\n",
    "#                 color = (255, 0, 0)\n",
    "#         elif left_blink == 1 or right_blink == 1:\n",
    "#             sleep = 0\n",
    "#             active = 0\n",
    "#             drowsy += 1\n",
    "#             if drowsy > 6:\n",
    "#                 status = \"Drowsy !!\"\n",
    "#                 color = (0, 0, 255)\n",
    "#         else:\n",
    "#             drowsy = 0\n",
    "#             sleep = 0\n",
    "#             active += 1\n",
    "#             if active > 6:\n",
    "#                 status = \"!! Active ...!\"\n",
    "#                 color = (0, 255, 0)\n",
    "        \n",
    "#         # Display status on the frame\n",
    "#         cv2.putText(frame, status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "\n",
    "#         # Draw facial landmarks on the face frame\n",
    "#         for n in range(0, 68):\n",
    "#             (x, y) = landmarks[n]\n",
    "#             cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "    \n",
    "#     # Perform OCR and print the extracted text\n",
    "#     perform_ocr(frame)\n",
    "\n",
    "#     # Show the original frame\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "#     # Show the frame with detected faces and landmarks\n",
    "#     if face_frame is not None:\n",
    "#         cv2\n",
    "\n",
    "#     cv2.imshow(\"Face Frame\", face_frame)\n",
    "\n",
    "#     # Check for 'q' key to exit the loop\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture object and close OpenCV windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make some changes in this code such that it can capture the frames every 5 sec gap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an alarm system that activates when the sleeping state is detected for 5 seconds, you can modify the while loop in the code to check if the status remains \"SLEEPING\" for 5 seconds or more. Once this condition is met, the alarm system will be triggered.\n",
    "\n",
    "Here's how you can modify the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from playsound import playsound\n",
    "import time  # Importing time library for timer\n",
    "\n",
    "# Initialize the video capture object (0 represents the default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face detector and facial landmarks predictor from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Define status variables for the blink detection\n",
    "sleep = 0\n",
    "drowsy = 0\n",
    "active = 0\n",
    "status = \"\"\n",
    "color = (0, 0, 0)\n",
    "\n",
    "# Define functions for computing distances and checking blinks\n",
    "def compute(ptA, ptB):\n",
    "    dist = np.linalg.norm(ptA - ptB)\n",
    "    return dist\n",
    "\n",
    "def blinked(a, b, c, d, e, f):\n",
    "    up = compute(b, d) + compute(c, e)\n",
    "    down = compute(a, f)\n",
    "    ratio = up / (2.0 * down)\n",
    "    \n",
    "    # Check for blinks based on ratio\n",
    "    if ratio > 0.25:\n",
    "        return 2\n",
    "    elif 0.21 <= ratio <= 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define a function to perform OCR on a frame and print the extracted text\n",
    "def perform_ocr(frame):\n",
    "    # Convert the frame to grayscale for better OCR accuracy\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding (binarization)\n",
    "    _, binary_frame = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Use Tesseract to extract text from the preprocessed frame\n",
    "    extracted_text = pytesseract.image_to_string(binary_frame, lang='eng')\n",
    "\n",
    "    # Print the extracted text in the console\n",
    "    print(\"Extracted Text:\", extracted_text)\n",
    "\n",
    "# Initialize the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Continuously read frames from the video capture object\n",
    "while True:\n",
    "    # Calculate elapsed time since the start of the loop\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Check if 5 seconds have passed since the last frame was processed\n",
    "    if elapsed_time >= 2:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Reset the timer\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Check if the frame is read successfully\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale frame\n",
    "        faces = detector(gray)\n",
    "        face_frame = frame.copy()\n",
    "        \n",
    "        # Process each detected face\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "\n",
    "            # Draw rectangles around detected faces\n",
    "            cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Get facial landmarks\n",
    "            landmarks = predictor(gray, face)\n",
    "            landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "            # Process eye blinks\n",
    "            left_blink = blinked(landmarks[36], landmarks[37], landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "            right_blink = blinked(landmarks[42], landmarks[43], landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "\n",
    "            # Judge the eye blinks\n",
    "            if left_blink == 0 or right_blink == 0:\n",
    "                sleep += 1\n",
    "                drowsy = 0\n",
    "                active = 0\n",
    "                if sleep > 6:\n",
    "                    status = \"SLEEPING\"\n",
    "                    color = (255, 0, 0)\n",
    "                    # Play alarm sound when the status is \"SLEEPING\"\n",
    "                    playsound(\"alarm.wav\")\n",
    "\n",
    "            elif left_blink == 1 or right_blink == 1:\n",
    "                sleep = 0\n",
    "                active = 0\n",
    "                drowsy += 1\n",
    "                if drowsy > 6:\n",
    "                    status = \"Drowsy\"\n",
    "                    color = (0, 0, 255)\n",
    "            else:\n",
    "                drowsy = 0\n",
    "                sleep = 0\n",
    "                active += 1\n",
    "                if active > 6:\n",
    "                    status = \"Active\"\n",
    "                    color = (0, 255, 0)\n",
    "\n",
    "            # Display status on the frame\n",
    "            cv2.putText(frame, status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "\n",
    "            # Draw facial landmarks on the face frame\n",
    "            for n in range(0, 68):\n",
    "                (x, y) = landmarks[n]\n",
    "                cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "        \n",
    "        # Perform OCR and print the extracted text\n",
    "        perform_ocr(frame)\n",
    "\n",
    "        # Show the original frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        # Show the frame with detected faces and landmarks\n",
    "        cv2.imshow(\"Face Frame\", face_frame)\n",
    "\n",
    "    # Check for 'q' key to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in above code add alarm system when sleeping state is for 5 sec \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an alarm system that activates when the sleeping state is detected for 5 seconds, you can modify the while loop in the code to check if the status remains \"SLEEPING\" for 5 seconds or more. Once this condition is met, the alarm system will be triggered.\n",
    "\n",
    "Here's how you can modify the code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "A new variable, sleep_start_time, is introduced to record the time when the sleeping state is first detected.\n",
    "When the status variable is set to \"SLEEPING\", the code checks if sleep_start_time is None to initialize it.\n",
    "The code then calculates the elapsed time since sleep_start_time and checks if it exceeds 5 seconds.\n",
    "If the sleeping state lasts for 5 seconds or more, the alarm sound is played using playsound, and sleep_start_time is reset to avoid multiple alarms.\n",
    "The rest of the code remains largely unchanged and functions as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from playsound import playsound\n",
    "import time\n",
    "\n",
    "# Initialize the video capture object (0 represents the default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face detector and facial landmarks predictor from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Define status variables for the blink detection\n",
    "sleep = 0\n",
    "drowsy = 0\n",
    "active = 0\n",
    "status = \"\"\n",
    "color = (0, 0, 0)\n",
    "\n",
    "# Define functions for computing distances and checking blinks\n",
    "def compute(ptA, ptB):\n",
    "    dist = np.linalg.norm(ptA - ptB)\n",
    "    return dist\n",
    "\n",
    "def blinked(a, b, c, d, e, f):\n",
    "    up = compute(b, d) + compute(c, e)\n",
    "    down = compute(a, f)\n",
    "    ratio = up / (2.0 * down)\n",
    "    \n",
    "    # Check for blinks based on ratio\n",
    "    if ratio > 0.25:\n",
    "        return 2\n",
    "    elif 0.21 <= ratio <= 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define a function to perform OCR on a frame and print the extracted text\n",
    "def perform_ocr(frame):\n",
    "    # Convert the frame to grayscale for better OCR accuracy\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding (binarization)\n",
    "    _, binary_frame = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Use Tesseract to extract text from the preprocessed frame\n",
    "    extracted_text = pytesseract.image_to_string(binary_frame, lang='eng')\n",
    "\n",
    "    # Print the extracted text in the console\n",
    "    print(\"Extracted Text:\", extracted_text)\n",
    "\n",
    "# Continuously read frames from the video capture object\n",
    "sleep_start_time = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector(gray)\n",
    "    face_frame = frame.copy()\n",
    "    \n",
    "    # Process each detected face\n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "\n",
    "        # Draw rectangles around detected faces\n",
    "        cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Get facial landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        # Process eye blinks\n",
    "        left_blink = blinked(landmarks[36], landmarks[37], landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "        right_blink = blinked(landmarks[42], landmarks[43], landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "\n",
    "        # Judge the eye blinks\n",
    "        if left_blink == 0 or right_blink == 0:\n",
    "            sleep += 1\n",
    "            drowsy = 0\n",
    "            active = 0\n",
    "            if sleep > 6:\n",
    "                status = \"SLEEPING\"\n",
    "                color = (255, 0, 0)\n",
    "                \n",
    "                # Record the time when sleep is first detected\n",
    "                if sleep_start_time is None:\n",
    "                    sleep_start_time = time.time()\n",
    "\n",
    "        elif left_blink == 1 or right_blink == 1:\n",
    "            sleep = 0\n",
    "            active = 0\n",
    "            drowsy += 1\n",
    "            if drowsy > 6:\n",
    "                status = \"Drowsy\"\n",
    "                color = (0, 0, 255)\n",
    "                \n",
    "                # Reset sleep_start_time if not in sleeping state\n",
    "                sleep_start_time = None\n",
    "        else:\n",
    "            drowsy = 0\n",
    "            sleep = 0\n",
    "            active += 1\n",
    "            if active > 6:\n",
    "                status = \"Active\"\n",
    "                color = (0, 255, 0)\n",
    "                \n",
    "                # Reset sleep_start_time if not in sleeping state\n",
    "                sleep_start_time = None\n",
    "\n",
    "        # Check if the sleeping state has lasted for 5 seconds or more\n",
    "        if status == \"SLEEPING\" and sleep_start_time:\n",
    "            elapsed_time = time.time() - sleep_start_time\n",
    "            if elapsed_time >= 3:\n",
    "                # Play alarm sound when the sleeping state is detected for 3 seconds or more\n",
    "                playsound(\"alarm.wav\")\n",
    "                \n",
    "                # Reset sleep_start_time to avoid multiple alarms\n",
    "                sleep_start_time = None\n",
    "        \n",
    "        # Display status on the frame\n",
    "        cv2.putText(frame, status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "\n",
    "        # Draw facial landmarks on the face frame\n",
    "        for n in range(0, 68):\n",
    "            (x, y) = landmarks[n]\n",
    "            cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "    \n",
    "    # Perform OCR and print the extracted text\n",
    "    perform_ocr(frame)\n",
    "\n",
    "    # Show the original frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Show the frame with detected faces and landmarks\n",
    "    cv2.imshow(\"Face Frame\", face_frame)\n",
    "\n",
    "    # Check for 'q' key to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the above code : Detect Text in Images with Python - pytesseract in the above code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the code to detect text in images using Python's pytesseract, you can incorporate the necessary functions and workflow for OCR (Optical Character Recognition) within the existing code. The following steps will guide you on how to achieve this:\n",
    "\n",
    "Import Necessary Libraries: You already have the required libraries for pytesseract and cv2 imported.\n",
    "\n",
    "Define a Function to Perform OCR: The function perform_ocr(frame) is already defined in your code. It uses pytesseract to extract text from a preprocessed frame.\n",
    "\n",
    "Perform OCR on the Frame: The function is called in each iteration of the while loop to perform OCR on the current frame.\n",
    "\n",
    "Print Extracted Text: The function prints the text extracted from each frame using print().\n",
    "\n",
    "Here is a revised version of your existing code with added comments to guide you:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "The perform_ocr function is used to perform OCR on the current frame and print the extracted text.\n",
    "The function is called on each frame within the while loop.\n",
    "The perform_ocr function converts the frame to grayscale and applies thresholding before using pytesseract to extract text.\n",
    "The function then prints the extracted text to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from playsound import playsound\n",
    "import time\n",
    "\n",
    "# Initialize the video capture object (0 represents the default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face detector and facial landmarks predictor from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Define status variables for the blink detection\n",
    "sleep = 0\n",
    "drowsy = 0\n",
    "active = 0\n",
    "status = \"\"\n",
    "color = (0, 0, 0)\n",
    "sleep_start_time = None\n",
    "\n",
    "# Define a function for computing distances and checking blinks\n",
    "def compute(ptA, ptB):\n",
    "    dist = np.linalg.norm(ptA - ptB)\n",
    "    return dist\n",
    "\n",
    "def blinked(a, b, c, d, e, f):\n",
    "    up = compute(b, d) + compute(c, e)\n",
    "    down = compute(a, f)\n",
    "    ratio = up / (2.0 * down)\n",
    "    \n",
    "    # Check for blinks based on the eye aspect ratio\n",
    "    if ratio > 0.25:\n",
    "        return 2\n",
    "    elif 0.21 <= ratio <= 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define a function to perform OCR on a frame and print the extracted text\n",
    "def perform_ocr(frame):\n",
    "    # Convert the frame to grayscale for better OCR accuracy\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding (binarization) for better text extraction\n",
    "    _, binary_frame = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Use pytesseract to extract text from the preprocessed frame\n",
    "    extracted_text = pytesseract.image_to_string(binary_frame, lang='eng')\n",
    "\n",
    "    # Print the extracted text in the console\n",
    "    print(\"Extracted Text:\", extracted_text)\n",
    "\n",
    "# Continuously read frames from the video capture object\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector(gray)\n",
    "    face_frame = frame.copy()\n",
    "    \n",
    "    # Process each detected face\n",
    "    for face in faces:\n",
    "        # Get coordinates of the face\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "\n",
    "        # Draw rectangles around detected faces\n",
    "        cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Get facial landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        # Process eye blinks\n",
    "        left_blink = blinked(landmarks[36], landmarks[37], landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "        right_blink = blinked(landmarks[42], landmarks[43], landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "\n",
    "        # Judge the eye blinks\n",
    "        if left_blink == 0 or right_blink == 0:\n",
    "            sleep += 1\n",
    "            drowsy = 0\n",
    "            active = 0\n",
    "            if sleep > 6:\n",
    "                status = \"SLEEPING\"\n",
    "                color = (255, 0, 0)\n",
    "                \n",
    "                # Record the time when sleep is first detected\n",
    "                if sleep_start_time is None:\n",
    "                    sleep_start_time = time.time()\n",
    "        elif left_blink == 1 or right_blink == 1:\n",
    "            sleep = 0\n",
    "            active = 0\n",
    "            drowsy += 1\n",
    "            if drowsy > 6:\n",
    "                status = \"Drowsy\"\n",
    "                color = (0, 0, 255)\n",
    "                \n",
    "                # Reset sleep_start_time if not in sleeping state\n",
    "                sleep_start_time = None\n",
    "        else:\n",
    "            drowsy = 0\n",
    "            sleep = 0\n",
    "            active += 1\n",
    "            if active > 6:\n",
    "                status = \"Active\"\n",
    "                color = (0, 255, 0)\n",
    "                \n",
    "                # Reset sleep_start_time if not in sleeping state\n",
    "                sleep_start_time = None\n",
    "        \n",
    "        # Check if the sleeping state has lasted for 5 seconds or more\n",
    "        if status == \"SLEEPING\" and sleep_start_time:\n",
    "            elapsed_time = time.time() - sleep_start_time\n",
    "            if elapsed_time >= 5:\n",
    "                # Play alarm sound when the sleeping state is detected for 5 seconds or more\n",
    "                playsound(\"alarm.wav\")\n",
    "                \n",
    "                # Reset sleep_start_time to avoid multiple alarms\n",
    "                sleep_start_time = None\n",
    "\n",
    "        # Display status on the frame\n",
    "        cv2.putText(frame, status, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "\n",
    "        # Draw facial landmarks on the face frame\n",
    "        for n in range(0, 68):\n",
    "            (x, y) = landmarks[n]\n",
    "            cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "    \n",
    "    # Perform OCR on the frame and print the extracted text\n",
    "    perform_ocr(frame)\n",
    "\n",
    "    # Show the original frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Show the frame with detected faces and landmarks\n",
    "    cv2.imshow(\"Face Frame\", face_frame)\n",
    "\n",
    "    # Check for 'q' key to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b9421b5222da2867aabbb111c01a47ecd976a453d0e487de23fa3aaa8e98ee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
